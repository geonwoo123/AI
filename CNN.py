import numpy as np

import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms

from torchsummary import summary
from tqdm import tqdm
import matplotlib.pyplot as plt

#//-------------------------------------------------------------------------
# Global Variable For training
# You just use the following hyper-parameters
BATCH_SIZE = 100                      #í•œë²ˆì— ëª¨ë¸ì— ì…ë ¥ë˜ëŠ” ë°ì´í„°ê°œìˆ˜
NUM_EPOCH = 50                        #ì „ì²´ ë°ì´í„°ì…‹ì„ ëª‡ë²ˆ ë°˜ë³µí•˜ì—¬ í•™ìŠµí• ì§€ ë‚˜íƒ€ëƒ„
LEARNING_RATE = 0.01                  #ëª¨ë¸ì´ í•™ìŠµí•˜ëŠ” ì†ë„ ì¡°ì ˆ, ë¹ ë¥¼ìˆ˜ë¡ ë¹ ë¥´ì§€ë§Œ ë¹ ë¥´ë‹¤ê³  ìµœì í™” ë˜ëŠ”ê±´ ì•„ë‹˜
CRITERION = nn.CrossEntropyLoss()     #ì†ì‹¤í•¨ìˆ˜, í¬ë¡œìŠ¤ì—”íŠ¸ë¡œí”¼ë¡œ í™•ë¥ ë¡œì„œ í‰ê°€
#-----------------------------------------------------------------------------
# CIFAR10 Dataset
train_dataset = dsets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=True)
test_dataset = dsets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor())

train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)   #ë°ì´í„°ì…‹ ë¡œë“œ ë° í›ˆë ¨ê³¼ ë°ìŠ¤íŠ¸ì— í•„ìš”í•œ ë°ì´í„° ì¤€ë¹„
#------------------------------------------------------------------------------
def fit(model,train_loader):
    model.train()
    device = next(model.parameters()).device.index
    optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)
    losses = []
    for i, data in enumerate(train_loader):
        image = data[0].type(torch.FloatTensor).cuda(device)
        label = data[1].type(torch.LongTensor).cuda(device)

        pred_label = model(image)
        loss = CRITERION(pred_label, label)
        losses.append(loss.item())

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    avg_loss = sum(losses)/len(losses)
    return avg_loss                                        #ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê·  ì†ì‹¤ê°’ ë°˜í™˜
#----------------------------------------------------------------------------------------------
def eval(model, test_loader):
    model.eval()
    device = next(model.parameters()).device.index
    pred_labels = []
    real_labels = []

    for i, data in enumerate(test_loader):
        image = data[0].type(torch.FloatTensor).cuda(device)
        label = data[1].type(torch.LongTensor).cuda(device)
        real_labels += list(label.cpu().detach().numpy())

        pred_label = model(image)
        pred_label = list(pred_label.cpu().detach().numpy())
        pred_labels += pred_label

    real_labels = np.array(real_labels)
    pred_labels = np.array(pred_labels)
    pred_labels = pred_labels.argmax(axis=1)
    acc = sum(real_labels==pred_labels)/len(real_labels)*100
    
    return acc                      #ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •í•˜ê³ ,  ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ê°’ ë¹„êµí•˜ì—¬ ì •í™•ë„ë¥¼ ë°˜í™˜í•œë‹¤.

#---------------------------------------------------------------------------------------------------


class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.convol_1 = nn.Conv2d(3, 8, kernel_size = 5)   # 32x32 -> 28x28ìœ¼ë¡œ ë§Œë“¤ì–´ì¤Œ (3:ì…ë ¥ì±„ë„ìˆ˜, 8:ì¶œë ¥ì±„ë„ìˆ˜,kernet:í•„í„°í¬ê¸°, strideë‘ channelì€ ê³ ì •ì´ë‹ˆ ìƒëµ)
        self.relu_1 = nn.ReLU()

        self.convol_2 = nn.Conv2d(8, 8, kernel_size = 5)   # 28x28 -> 24x24
        self.relu_2 = nn.ReLU()

        self.pool_1 = nn.MaxPool2d(2)  # 24x24 -> 12x12 (í’€ë§ ë ˆì´ì–´ì˜ í¬ê¸°ë¥¼ 2ë¡œ í•´ì¤Œ ì¦‰ í¬ê¸°ë¥¼ ì ˆë°˜ìœ¼ë¡œ ë§Œë“¬)

        self.convol_3 = nn.Conv2d(8, 16, kernel_size = 5)  # 12x12 -> 8x8
        self.relu_3 = nn.ReLU()

        self.convol_4 = nn.Conv2d(16, 16, kernel_size = 5) # 8x8 -> 4x4
        self.relu_4 = nn.ReLU()

        self.pool_2 = nn.MaxPool2d(2)  # 4x4 -> 2x2

        self.fc = nn.Linear(16*2*2, 10)

    def forward(self, x):
        x = self.relu_1(self.convol_1(x))
        x = self.relu_2(self.convol_2(x))
        x = self.pool_1(x)

        x = self.relu_3(self.convol_3(x))
        x = self.relu_4(self.convol_4(x))
        x = self.pool_2(x)

        x = x.view(x.size(0), -1)  #convolution layerì „ë¶€ ê±°ì¹œêµ¬ fcì—°ê²° í•´ì•¼í•˜ë¯€ë¡œ flattenì‘ì—… ì‹¤ì‹œí•˜ê¸°
        out = self.fc(x)
        return out

#-----------------------------------------------------------------------------------
cnn_model = SimpleCNN().cuda()
train_loss2 = []
test_accuracy2 = []
for epoch in tqdm(range(NUM_EPOCH)):
    train_loss2.append(fit(cnn_model, train_loader))
    test_accuracy2.append(eval(cnn_model, test_loader))
summary(cnn_model, input_size = (3,32,32))

print("\nğŸ” [SimpleCNN] ê° ë ˆì´ì–´ë³„ íŒŒë¼ë¯¸í„° ìˆ˜ (Weight / Bias)\n" + "-"*60)
total_weight = 0
total_bias = 0

for name, param in cnn_model.named_parameters():
    param_count = param.numel()
    if 'weight' in name:
        print(f"{name:<35} | Weight Params: {param_count}")
        total_weight += param_count
    elif 'bias' in name:
        print(f"{name:<35} | Bias Params:   {param_count}")
        total_bias += param_count

print("-"*60)
print(f"ì´ ê°€ì¤‘ì¹˜(Weights): {total_weight:,}")
print(f"ì´ ë°”ì´ì–´ìŠ¤(Biases): {total_bias:,}")
print(f"ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_weight + total_bias:,}")


# í•™ìŠµ ì†ì‹¤ ì‹œê°í™”
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.plot(train_loss2, label='Train Loss', color='blue')
plt.title('Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid(True)
plt.legend()

# í…ŒìŠ¤íŠ¸ ì •í™•ë„ ì‹œê°í™”
plt.subplot(1,2,2)
plt.plot(test_accuracy2, label='Test Accuracy', color='green')
plt.title('Test Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.grid(True)
plt.legend()

plt.tight_layout()
plt.show()
